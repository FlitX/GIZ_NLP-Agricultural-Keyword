{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPx7su0Jj1b+jwpuA1R4yD5"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73r59Z5FoKyq","executionInfo":{"status":"ok","timestamp":1605972954191,"user_tz":-60,"elapsed":46477,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}},"outputId":"8f656868-7f49-4552-8b2e-948b27ee5b11"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQF-5rXn8FuI","executionInfo":{"status":"ok","timestamp":1605972970791,"user_tz":-60,"elapsed":14689,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}},"outputId":"82064d92-2e7b-440d-c3c2-cfb0a45b0866"},"source":["!pip install wavio\n","!pip install kapre==0.3.4"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting wavio\n","  Downloading https://files.pythonhosted.org/packages/e6/98/8bf5ea39a3385cc806ba1146a280a113835e5df3b0ad25ca95eea8352040/wavio-0.0.4-py2.py3-none-any.whl\n","Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from wavio) (1.18.5)\n","Installing collected packages: wavio\n","Successfully installed wavio-0.0.4\n","Collecting kapre==0.3.4\n","  Downloading https://files.pythonhosted.org/packages/5b/a3/a80d9e09b67a728c167b787917813f4d80e0ad033697f9db237030f9a454/kapre-0.3.4.tar.gz\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting librosa>=0.7.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/4d/c22d8ca74ca2c13cd4ac430fa353954886104321877b65fa871939e78591/librosa-0.8.0.tar.gz (183kB)\n","\u001b[K     |████████████████████████████████| 184kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.6/dist-packages (from kapre==0.3.4) (2.3.0)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.6/dist-packages (from kapre==0.3.4) (1.18.5)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.2->kapre==0.3.4) (2.1.9)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.2->kapre==0.3.4) (1.4.1)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.2->kapre==0.3.4) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.2->kapre==0.3.4) (0.17.0)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.2->kapre==0.3.4) (4.4.2)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.2->kapre==0.3.4) (0.2.2)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.2->kapre==0.3.4) (0.48.0)\n","Collecting soundfile>=0.9.0\n","  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n","Collecting pooch>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/11/d7a1dc8173a4085759710e69aae6e070d0d432db84013c7c343e4e522b76/pooch-1.2.0-py3-none-any.whl (47kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (1.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (3.12.4)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (0.10.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (1.6.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (1.15.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (1.1.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (3.3.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (2.10.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (0.2.0)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (2.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (0.35.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (1.33.2)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (0.3.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (1.12.1)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.0->kapre==0.3.4) (2.3.0)\n","Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa>=0.7.2->kapre==0.3.4) (0.31.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa>=0.7.2->kapre==0.3.4) (50.3.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa>=0.7.2->kapre==0.3.4) (1.14.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa>=0.7.2->kapre==0.3.4) (20.4)\n","Collecting appdirs\n","  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa>=0.7.2->kapre==0.3.4) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (1.7.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (3.3.3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (0.4.2)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (1.17.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (1.0.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa>=0.7.2->kapre==0.3.4) (2.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->pooch>=1.0->librosa>=0.7.2->kapre==0.3.4) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre==0.3.4) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre==0.3.4) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre==0.3.4) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pooch>=1.0->librosa>=0.7.2->kapre==0.3.4) (3.0.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (2.0.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (3.4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.0->kapre==0.3.4) (0.4.8)\n","Building wheels for collected packages: kapre\n","  Building wheel for kapre (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kapre: filename=kapre-0.3.4-cp36-none-any.whl size=20608 sha256=d0c786597ec31de8aea68d8a2208ac4b98ab347623859d54f83887cc2fd2bea9\n","  Stored in directory: /root/.cache/pip/wheels/f8/9e/dc/cc6f4989c58eee2913abac4fab60723ff91aa2a06c6de4280f\n","Successfully built kapre\n","Building wheels for collected packages: librosa\n","  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for librosa: filename=librosa-0.8.0-cp36-none-any.whl size=201376 sha256=f4ed4eaecb2c9fdd84d60011738d9e29a3ba6db6c925b1711da9cb56a6883357\n","  Stored in directory: /root/.cache/pip/wheels/ee/10/1e/382bb4369e189938d5c02e06d10c651817da8d485bfd1647c9\n","Successfully built librosa\n","Installing collected packages: soundfile, appdirs, pooch, librosa, kapre\n","  Found existing installation: librosa 0.6.3\n","    Uninstalling librosa-0.6.3:\n","      Successfully uninstalled librosa-0.6.3\n","  Found existing installation: kapre 0.1.3.1\n","    Uninstalling kapre-0.1.3.1:\n","      Successfully uninstalled kapre-0.1.3.1\n","Successfully installed appdirs-1.4.4 kapre-0.3.4 librosa-0.8.0 pooch-1.2.0 soundfile-0.10.3.post1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3zGnslWyA0B3","executionInfo":{"status":"ok","timestamp":1605972980771,"user_tz":-60,"elapsed":3563,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}}},"source":["import librosa, librosa.display"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzfpmxjMG89P","executionInfo":{"status":"ok","timestamp":1605972982404,"user_tz":-60,"elapsed":3054,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}}},"source":["import matplotlib.pyplot as plt\n","from scipy.io import wavfile\n","import argparse\n","import os\n","from glob import glob\n","import numpy as np\n","import pandas as pd\n","from librosa.core import resample, to_mono\n","from tqdm import tqdm\n","import wavio\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import TimeDistributed, LayerNormalization\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","import kapre\n","from kapre.composed import get_melspectrogram_layer\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","#from models import Conv1D, Conv2D, LSTM\n","import warnings"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3_8S52cwG9PJ","executionInfo":{"status":"ok","timestamp":1605972987798,"user_tz":-60,"elapsed":1390,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}}},"source":["os.chdir('/content/drive/MyDrive/GLP')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ybxIiavG9ZY","executionInfo":{"status":"ok","timestamp":1605972991326,"user_tz":-60,"elapsed":2717,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}},"outputId":"48665731-8472-434b-c67b-8489b85612d8"},"source":["!ls"],"execution_count":6,"outputs":[{"output_type":"stream","text":["AdditionalUtterances.zip  GLP_data_PPP.ipynb\t      raw_test\n","audio_files\t\t  keywords\t\t      raw_train\n","audio_files.zip\t\t  latest_keywords\t      SampleSubmission.csv\n","clean_2.0\t\t  logs\t\t\t      submission\n","clean.py\t\t  nlp_keywords\t\t      Train.csv\n","GLP1.py\t\t\t  nlp_keywords_29Oct2020.zip\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qCFHtQ3uG83g","executionInfo":{"status":"ok","timestamp":1605975744521,"user_tz":-60,"elapsed":1127,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}}},"source":["def envelope(y, rate, threshold):\n","    mask = []\n","    y = pd.Series(y).apply(np.abs)\n","    y_mean = y.rolling(window=int(rate/30),\n","                       min_periods=1,\n","                       center=True).max()\n","    for mean in y_mean:\n","        if mean > threshold:\n","            mask.append(True)\n","        else:\n","            mask.append(False)\n","    return mask, y_mean\n","\n","\n","def downsample_mono(path, sr):\n","    obj = wavio.read(path)\n","    wav = obj.data.astype(np.float32, order='F')\n","    rate = obj.rate\n","    try:\n","        channel = wav.shape[1]\n","        if channel == 2:\n","            wav = to_mono(wav.T)\n","        elif channel == 1:\n","            wav = to_mono(wav.reshape(-1))\n","    except IndexError:\n","        wav = to_mono(wav.reshape(-1))\n","        pass\n","    except Exception as exc:\n","        raise exc\n","    wav = resample(wav, rate, sr)\n","    wav = wav.astype(np.int16)\n","    return sr, wav\n","\n","\n","def save_sample(sample, rate, target_dir, fn, ix):\n","    fn = fn.split('.wav')[0]\n","    dst_path = os.path.join(target_dir.split('.')[0], fn+'_{}.wav'.format(str(ix)))\n","    if os.path.exists(dst_path):\n","        return\n","    wavfile.write(dst_path, rate, sample)\n","\n","\n","def check_dir(path):\n","    if os.path.exists(path) is False:\n","        os.mkdir(path)\n","\n","\n","def split_wavs(args):\n","    src_root = args.src_root\n","    dst_root = args.dst_root\n","    dt = args.delta_time\n","\n","    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n","    wav_paths = [x for x in wav_paths if '.wav' in x]\n","    dirs = os.listdir(src_root)\n","    check_dir(dst_root)\n","    classes = os.listdir(src_root)\n","    for _cls in classes:\n","        target_dir = os.path.join(dst_root, _cls)\n","        check_dir(target_dir)\n","        src_dir = os.path.join(src_root, _cls)\n","        for fn in tqdm(os.listdir(src_dir)):\n","            src_fn = os.path.join(src_dir, fn)\n","            rate, wav = downsample_mono(src_fn, args.sr)\n","            mask, y_mean = envelope(wav, rate, threshold=args.threshold)\n","            wav = wav[mask]\n","            delta_sample = int(dt*rate)\n","\n","            # cleaned audio is less than a single sample\n","            # pad with zeros to delta_sample size\n","            if wav.shape[0] < delta_sample:\n","                sample = np.zeros(shape=(delta_sample,), dtype=np.int16)\n","                sample[:wav.shape[0]] = wav\n","                save_sample(sample, rate, target_dir, fn, 0)\n","            # step through audio and save every delta_sample\n","            # discard the ending audio if it is too short\n","            else:\n","                trunc = wav.shape[0] % delta_sample\n","                for cnt, i in enumerate(np.arange(0, wav.shape[0]-trunc, delta_sample)):\n","                    start = int(i)\n","                    stop = int(i + delta_sample)\n","                    sample = wav[start:stop]\n","                    save_sample(sample, rate, target_dir, fn, cnt)\n","\n","\n","def test_threshold(args):\n","    src_root = args.src_root\n","    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n","    wav_path = [x for x in wav_paths if args.fn in x]\n","    if len(wav_path) != 1:\n","        print('audio file not found for sub-string: {}'.format(args.fn))\n","        return\n","    rate, wav = downsample_mono(wav_path[0], args.sr)\n","    mask, env = envelope(wav, rate, threshold=args.threshold)\n","    plt.figure(figsize=(15,10))\n","    plt.style.use('ggplot')\n","    plt.title('Signal Envelope, Threshold = {}'.format(str(args.threshold)))\n","    plt.plot(wav[np.logical_not(mask)], color='r', label='remove')\n","    plt.plot(wav[mask], color='c', label='keep')\n","    plt.plot(env, color='m', label='envelope')\n","    plt.grid(False)\n","    plt.legend(loc='best')\n","    plt.show()\n","\n","\n","if __name__ == '__main__':\n","\n","    parser = argparse.ArgumentParser(description='Cleaning audio data')\n","    parser.add_argument('--src_root', type=str, default='raw_test',\n","                        help='directory of audio files in total duration')\n","    parser.add_argument('--dst_root', type=str, default='clean_test',\n","                        help='directory to put audio files split by delta_time')\n","    parser.add_argument('--delta_time', '-dt', type=float, default=1.0,\n","                        help='time in seconds to sample audio')\n","    parser.add_argument('--sr', type=int, default=22050,\n","                        help='rate to downsample audio')\n","\n","    parser.add_argument('--fn', type=str, default='CRNVLST.wav',\n","                        help='file to plot over time to check magnitude')\n","    parser.add_argument('--threshold', type=str, default=200,\n","                        help='threshold magnitude for np.int16 dtype')\n","    args, _ = parser.parse_known_args()\n"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjhSWTEOG9kn","executionInfo":{"status":"ok","timestamp":1605975275257,"user_tz":-60,"elapsed":1426809,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}},"outputId":"5387612c-5c23-4bb2-bef8-d7a97aa46d3c"},"source":["split_wavs(args)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["100%|██████████| 55/55 [00:16<00:00,  3.36it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.24it/s]\n","100%|██████████| 49/49 [00:15<00:00,  3.16it/s]\n","100%|██████████| 33/33 [00:10<00:00,  3.10it/s]\n","100%|██████████| 40/40 [00:12<00:00,  3.30it/s]\n","100%|██████████| 33/33 [00:10<00:00,  3.17it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.16it/s]\n","100%|██████████| 36/36 [00:11<00:00,  3.21it/s]\n","100%|██████████| 32/32 [00:10<00:00,  3.09it/s]\n","100%|██████████| 29/29 [00:08<00:00,  3.44it/s]\n","100%|██████████| 30/30 [00:09<00:00,  3.15it/s]\n","100%|██████████| 51/51 [00:15<00:00,  3.28it/s]\n","100%|██████████| 33/33 [00:10<00:00,  3.22it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.33it/s]\n","100%|██████████| 51/51 [00:16<00:00,  3.18it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.24it/s]\n","100%|██████████| 29/29 [00:08<00:00,  3.51it/s]\n","100%|██████████| 31/31 [00:08<00:00,  3.45it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.25it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.30it/s]\n","100%|██████████| 56/56 [00:16<00:00,  3.43it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.36it/s]\n","100%|██████████| 50/50 [00:16<00:00,  3.05it/s]\n","100%|██████████| 27/27 [00:08<00:00,  3.35it/s]\n","100%|██████████| 45/45 [00:14<00:00,  3.20it/s]\n","100%|██████████| 30/30 [00:09<00:00,  3.11it/s]\n","100%|██████████| 4/4 [00:01<00:00,  2.44it/s]\n","100%|██████████| 35/35 [00:10<00:00,  3.25it/s]\n","100%|██████████| 33/33 [00:10<00:00,  3.15it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.46it/s]\n","100%|██████████| 34/34 [00:10<00:00,  3.38it/s]\n","100%|██████████| 34/34 [00:10<00:00,  3.24it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.36it/s]\n","100%|██████████| 25/25 [00:07<00:00,  3.51it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.33it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.37it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.25it/s]\n","100%|██████████| 6/6 [00:01<00:00,  3.35it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.34it/s]\n","100%|██████████| 5/5 [00:01<00:00,  3.35it/s]\n","100%|██████████| 28/28 [00:08<00:00,  3.43it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.43it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.19it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.36it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.48it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.50it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.35it/s]\n","100%|██████████| 29/29 [00:08<00:00,  3.34it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.43it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.22it/s]\n","100%|██████████| 29/29 [00:08<00:00,  3.29it/s]\n","100%|██████████| 57/57 [00:17<00:00,  3.31it/s]\n","100%|██████████| 36/36 [00:10<00:00,  3.35it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.33it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.82it/s]\n","100%|██████████| 27/27 [00:08<00:00,  3.16it/s]\n","100%|██████████| 34/34 [00:10<00:00,  3.23it/s]\n","100%|██████████| 8/8 [00:03<00:00,  2.54it/s]\n","100%|██████████| 33/33 [00:11<00:00,  2.96it/s]\n","100%|██████████| 28/28 [00:08<00:00,  3.26it/s]\n","100%|██████████| 30/30 [00:09<00:00,  3.24it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.47it/s]\n","100%|██████████| 31/31 [00:08<00:00,  3.50it/s]\n","100%|██████████| 35/35 [00:10<00:00,  3.35it/s]\n","100%|██████████| 29/29 [00:08<00:00,  3.57it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.24it/s]\n","100%|██████████| 31/31 [00:08<00:00,  3.53it/s]\n","100%|██████████| 30/30 [00:09<00:00,  3.22it/s]\n","100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n","100%|██████████| 44/44 [00:13<00:00,  3.26it/s]\n","100%|██████████| 45/45 [00:13<00:00,  3.41it/s]\n","100%|██████████| 35/35 [00:10<00:00,  3.32it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.46it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.40it/s]\n","100%|██████████| 36/36 [00:10<00:00,  3.49it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.33it/s]\n","100%|██████████| 4/4 [00:00<00:00,  4.62it/s]\n","100%|██████████| 41/41 [00:12<00:00,  3.38it/s]\n","100%|██████████| 51/51 [00:16<00:00,  3.14it/s]\n","100%|██████████| 51/51 [00:15<00:00,  3.28it/s]\n","100%|██████████| 28/28 [00:08<00:00,  3.17it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.50it/s]\n","100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n","100%|██████████| 37/37 [00:11<00:00,  3.13it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.17it/s]\n","100%|██████████| 59/59 [00:18<00:00,  3.19it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.34it/s]\n","100%|██████████| 28/28 [00:08<00:00,  3.37it/s]\n","100%|██████████| 53/53 [00:15<00:00,  3.36it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.36it/s]\n","100%|██████████| 25/25 [00:07<00:00,  3.46it/s]\n","100%|██████████| 32/32 [00:10<00:00,  3.07it/s]\n","100%|██████████| 36/36 [00:10<00:00,  3.34it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.21it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.32it/s]\n","100%|██████████| 34/34 [00:10<00:00,  3.34it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.35it/s]\n","100%|██████████| 31/31 [00:10<00:00,  2.95it/s]\n","100%|██████████| 32/32 [00:08<00:00,  3.56it/s]\n","100%|██████████| 39/39 [00:10<00:00,  3.58it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.23it/s]\n","100%|██████████| 27/27 [00:07<00:00,  3.47it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.37it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.41it/s]\n","100%|██████████| 34/34 [00:10<00:00,  3.22it/s]\n","100%|██████████| 36/36 [00:10<00:00,  3.51it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.28it/s]\n","100%|██████████| 31/31 [00:10<00:00,  2.96it/s]\n","100%|██████████| 30/30 [00:09<00:00,  3.03it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.44it/s]\n","100%|██████████| 32/32 [00:10<00:00,  3.19it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.16it/s]\n","100%|██████████| 4/4 [00:01<00:00,  2.91it/s]\n","100%|██████████| 31/31 [00:08<00:00,  3.48it/s]\n","100%|██████████| 53/53 [00:15<00:00,  3.34it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.36it/s]\n","100%|██████████| 26/26 [00:07<00:00,  3.41it/s]\n","100%|██████████| 30/30 [00:08<00:00,  3.38it/s]\n","100%|██████████| 29/29 [00:09<00:00,  3.20it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.06it/s]\n","100%|██████████| 3/3 [00:01<00:00,  2.72it/s]\n","100%|██████████| 32/32 [00:10<00:00,  3.12it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.75it/s]\n","100%|██████████| 3/3 [00:01<00:00,  2.97it/s]\n","100%|██████████| 34/34 [00:10<00:00,  3.22it/s]\n","100%|██████████| 30/30 [00:08<00:00,  3.46it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.48it/s]\n","100%|██████████| 27/27 [00:08<00:00,  3.28it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.33it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.18it/s]\n","100%|██████████| 35/35 [00:10<00:00,  3.50it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.25it/s]\n","100%|██████████| 4/4 [00:01<00:00,  2.73it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.23it/s]\n","100%|██████████| 3/3 [00:01<00:00,  2.92it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.37it/s]\n","100%|██████████| 33/33 [00:09<00:00,  3.43it/s]\n","100%|██████████| 8/8 [00:02<00:00,  3.48it/s]\n","100%|██████████| 27/27 [00:08<00:00,  3.21it/s]\n","100%|██████████| 36/36 [00:11<00:00,  3.16it/s]\n","100%|██████████| 5/5 [00:01<00:00,  3.23it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.56it/s]\n","100%|██████████| 6/6 [00:01<00:00,  3.60it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.51it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.49it/s]\n","100%|██████████| 30/30 [00:08<00:00,  3.53it/s]\n","100%|██████████| 30/30 [00:08<00:00,  3.45it/s]\n","100%|██████████| 26/26 [00:08<00:00,  3.06it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.27it/s]\n","100%|██████████| 5/5 [00:01<00:00,  3.62it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.55it/s]\n","100%|██████████| 29/29 [00:08<00:00,  3.38it/s]\n","100%|██████████| 35/35 [00:10<00:00,  3.41it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.44it/s]\n","100%|██████████| 27/27 [00:07<00:00,  3.50it/s]\n","100%|██████████| 7/7 [00:01<00:00,  3.52it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.13it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.40it/s]\n","100%|██████████| 36/36 [00:10<00:00,  3.35it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.44it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.23it/s]\n","100%|██████████| 39/39 [00:11<00:00,  3.38it/s]\n","100%|██████████| 31/31 [00:09<00:00,  3.40it/s]\n","100%|██████████| 36/36 [00:10<00:00,  3.51it/s]\n","100%|██████████| 31/31 [00:08<00:00,  3.47it/s]\n","100%|██████████| 3/3 [00:01<00:00,  2.76it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.31it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.49it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.44it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.35it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.58it/s]\n","100%|██████████| 7/7 [00:02<00:00,  3.44it/s]\n","100%|██████████| 32/32 [00:10<00:00,  3.16it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.49it/s]\n","100%|██████████| 32/32 [00:10<00:00,  3.15it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.45it/s]\n","100%|██████████| 29/29 [00:09<00:00,  3.19it/s]\n","100%|██████████| 38/38 [00:10<00:00,  3.53it/s]\n","100%|██████████| 35/35 [00:10<00:00,  3.42it/s]\n","100%|██████████| 36/36 [00:10<00:00,  3.53it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.23it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.13it/s]\n","100%|██████████| 38/38 [00:11<00:00,  3.42it/s]\n","100%|██████████| 6/6 [00:01<00:00,  4.15it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.47it/s]\n","100%|██████████| 28/28 [00:07<00:00,  3.50it/s]\n","100%|██████████| 4/4 [00:01<00:00,  2.28it/s]\n","100%|██████████| 32/32 [00:09<00:00,  3.51it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.60it/s]\n","100%|██████████| 28/28 [00:09<00:00,  3.04it/s]\n","100%|██████████| 32/32 [00:10<00:00,  3.18it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.31it/s]\n","100%|██████████| 3/3 [00:00<00:00,  3.62it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HcUxkgchoInW","executionInfo":{"status":"ok","timestamp":1605975995712,"user_tz":-60,"elapsed":1278,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}},"outputId":"716efbf1-0633-4d1e-ada6-81d2c711aafb"},"source":["print('clean: '+ str(sum(len(files) for _, _, files in os.walk('clean'))))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["clean: 5600\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RctpTzApDZMf","executionInfo":{"status":"ok","timestamp":1605980972913,"user_tz":-60,"elapsed":1486,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}}},"source":["def Conv1D(N_CLASSES=193, SR=22050, DT=2.0):\n","    input_shape = (int(SR*DT), 1)\n","    i = get_melspectrogram_layer(input_shape=input_shape,\n","                                 n_mels=128,\n","                                 pad_end=True,\n","                                 n_fft=512,\n","                                 win_length=400,\n","                                 hop_length=160,\n","                                 sample_rate=SR,\n","                                 return_decibel=True,\n","                                 input_data_format='channels_last',\n","                                 output_data_format='channels_last')\n","    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n","    x = TimeDistributed(layers.Conv1D(8, kernel_size=(4), activation='tanh'), name='td_conv_1d_tanh')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_1')(x)\n","    x = TimeDistributed(layers.Conv1D(16, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_1')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_2')(x)\n","    x = TimeDistributed(layers.Conv1D(32, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_2')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_3')(x)\n","    x = TimeDistributed(layers.Conv1D(64, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_3')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), name='max_pool_2d_4')(x)\n","    x = TimeDistributed(layers.Conv1D(128, kernel_size=(4), activation='relu'), name='td_conv_1d_relu_4')(x)\n","    x = layers.GlobalMaxPooling2D(name='global_max_pooling_2d')(x)\n","    x = layers.Dropout(rate=0.1, name='dropout')(x)\n","    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n","    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n","    model = Model(inputs=i.input, outputs=o, name='1d_convolution')\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","\n","def Conv2D(N_CLASSES=193, SR=22050, DT=2.0):\n","    input_shape = (int(SR*DT), 1)\n","    i = get_melspectrogram_layer(input_shape=input_shape,\n","                                 n_mels=128,\n","                                 pad_end=True,\n","                                 n_fft=512,\n","                                 win_length=400,\n","                                 hop_length=160,\n","                                 sample_rate=SR,\n","                                 return_decibel=True,\n","                                 input_data_format='channels_last',\n","                                 output_data_format='channels_last')\n","    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n","    x = layers.Conv2D(8, kernel_size=(7,7), activation='tanh', padding='same', name='conv2d_tanh')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_1')(x)\n","    x = layers.Conv2D(16, kernel_size=(5,5), activation='relu', padding='same', name='conv2d_relu_1')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_2')(x)\n","    x = layers.Conv2D(16, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_2')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_3')(x)\n","    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_3')(x)\n","    x = layers.MaxPooling2D(pool_size=(2,2), padding='same', name='max_pool_2d_4')(x)\n","    x = layers.Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', name='conv2d_relu_4')(x)\n","    x = layers.Flatten(name='flatten')(x)\n","    x = layers.Dropout(rate=0.2, name='dropout')(x)\n","    x = layers.Dense(64, activation='relu', activity_regularizer=l2(0.001), name='dense')(x)\n","    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n","    model = Model(inputs=i.input, outputs=o, name='2d_convolution')\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","\n","def LSTM(N_CLASSES=193, SR=22050, DT=2.0):\n","    input_shape = (int(SR*DT), 1)\n","    i = get_melspectrogram_layer(input_shape=input_shape,\n","                                     n_mels=128,\n","                                     pad_end=True,\n","                                     n_fft=512,\n","                                     win_length=400,\n","                                     hop_length=160,\n","                                     sample_rate=SR,\n","                                     return_decibel=True,\n","                                     input_data_format='channels_last',\n","                                     output_data_format='channels_last',\n","                                     name='2d_convolution')\n","    x = LayerNormalization(axis=2, name='batch_norm')(i.output)\n","    x = TimeDistributed(layers.Reshape((-1,)), name='reshape')(x)\n","    s = TimeDistributed(layers.Dense(64, activation='tanh'),\n","                        name='td_dense_tanh')(x)\n","    x = layers.Bidirectional(layers.LSTM(32, return_sequences=True),\n","                             name='bidirectional_lstm')(s)\n","    x = layers.concatenate([s, x], axis=2, name='skip_connection')\n","    x = layers.Dense(64, activation='relu', name='dense_1_relu')(x)\n","    x = layers.MaxPooling1D(name='max_pool_1d')(x)\n","    x = layers.Dense(32, activation='relu', name='dense_2_relu')(x)\n","    x = layers.Flatten(name='flatten')(x)\n","    x = layers.Dropout(rate=0.2, name='dropout')(x)\n","    x = layers.Dense(32, activation='relu',\n","                         activity_regularizer=l2(0.001),\n","                         name='dense_3_relu')(x)\n","    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n","    model = Model(inputs=i.input, outputs=o, name='long_short_term_memory')\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    return model"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pAKzRCkGeFO","executionInfo":{"status":"ok","timestamp":1605980976367,"user_tz":-60,"elapsed":1551,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}}},"source":["class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, wav_paths, labels, sr, dt, n_classes,\n","                 batch_size=64, shuffle=True):\n","        self.wav_paths = wav_paths\n","        self.labels = labels\n","        self.sr = sr\n","        self.dt = dt\n","        self.n_classes = n_classes\n","        self.batch_size = batch_size\n","        self.shuffle = True\n","        self.on_epoch_end()\n","\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.wav_paths) / self.batch_size))\n","\n","\n","    def __getitem__(self, index):\n","        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n","\n","        wav_paths = [self.wav_paths[k] for k in indexes]\n","        labels = [self.labels[k] for k in indexes]\n","\n","        # generate a batch of time data\n","        X = np.empty((self.batch_size, int(self.sr*self.dt), 1), dtype=np.float32)\n","        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n","\n","        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n","            rate, wav = wavfile.read(path)\n","            X[i,] = wav.reshape(-1, 1)\n","            Y[i,] = to_categorical(label, num_classes=self.n_classes)\n","\n","        return X, Y\n","\n","\n","    def on_epoch_end(self):\n","        self.indexes = np.arange(len(self.wav_paths))\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","\n","def train(args):\n","    src_root = args.src_root\n","    sr = args.sample_rate\n","    dt = args.delta_time\n","    batch_size = args.batch_size\n","    model_type = args.model_type\n","    params = {'N_CLASSES':len(os.listdir(args.src_root)),\n","              'SR':sr,\n","              'DT':dt}\n","    models = {'conv1d':Conv1D(**params),\n","              'conv2d':Conv2D(**params),\n","              'lstm':  LSTM(**params)}\n","    assert model_type in models.keys(), '{} not an available model'.format(model_type)\n","    csv_path = os.path.join('logs', '{}_history.csv'.format(model_type))\n","\n","    wav_paths = glob('{}/**'.format(src_root), recursive=True)\n","    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n","    classes = sorted(os.listdir(args.src_root))\n","    le = LabelEncoder()\n","    le.fit(classes)\n","    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n","    labels = le.transform(labels)\n","    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n","                                                                  labels,\n","                                                                  test_size=0.1,\n","                                                                  random_state=0)\n","\n","    assert len(label_train) >= args.batch_size, 'Number of train samples must be >= batch_size'\n","    if len(set(label_train)) != params['N_CLASSES']:\n","        warnings.warn('Found {}/{} classes in training data. Increase data size or change random_state.'.format(len(set(label_train)), params['N_CLASSES']))\n","    if len(set(label_val)) != params['N_CLASSES']:\n","        warnings.warn('Found {}/{} classes in validation data. Increase data size or change random_state.'.format(len(set(label_val)), params['N_CLASSES']))\n","\n","    tg = DataGenerator(wav_train, label_train, sr, dt,\n","                       params['N_CLASSES'], batch_size=batch_size)\n","    vg = DataGenerator(wav_val, label_val, sr, dt,\n","                       params['N_CLASSES'], batch_size=batch_size)\n","    model = models[model_type]\n","    cp = ModelCheckpoint('models/{}.h5'.format(model_type), monitor='val_loss',\n","                         save_best_only=True, save_weights_only=False,\n","                         mode='auto', save_freq='epoch', verbose=1)\n","    csv_logger = CSVLogger(csv_path, append=False)\n","    model.fit(tg, validation_data=vg,\n","              epochs=30, verbose=1,\n","              callbacks=[csv_logger, cp])\n","\n","if __name__ == '__main__':\n","\n","    parser = argparse.ArgumentParser(description='Audio Classification Training')\n","    parser.add_argument('--model_type', type=str, default='lstm',\n","                        help='model to run. i.e. conv1d, conv2d, lstm')\n","    parser.add_argument('--src_root', type=str, default='clean_2.0',\n","                        help='directory of audio files in total duration')\n","    parser.add_argument('--batch_size', type=int, default=64,\n","                        help='batch size')\n","    parser.add_argument('--delta_time', '-dt', type=float, default=2.0,\n","                        help='time in seconds to sample audio')\n","    parser.add_argument('--sample_rate', '-sr', type=int, default=22050,\n","                        help='sample rate of clean audio')\n","    args, _ = parser.parse_known_args()\n"],"execution_count":52,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k3MceHmTDKpo","executionInfo":{"status":"ok","timestamp":1605984738348,"user_tz":-60,"elapsed":1203940,"user":{"displayName":"Felix Okibe","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhN1S7cK77upIlLJA994ZKBh2kGXFcdL8zFggal=s64","userId":"11803436423808863200"}},"outputId":"4dc7b6fe-cdd3-48cf-faf2-2151d606629b"},"source":["train(args)"],"execution_count":53,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:73: UserWarning: Found 146/193 classes in validation data. Increase data size or change random_state.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/30\n","66/66 [==============================] - ETA: 0s - loss: 5.2438 - accuracy: 0.0099 \n","Epoch 00001: val_loss improved from inf to 5.19451, saving model to models/lstm.h5\n","66/66 [==============================] - 1050s 16s/step - loss: 5.2438 - accuracy: 0.0099 - val_loss: 5.1945 - val_accuracy: 0.0089\n","Epoch 2/30\n","66/66 [==============================] - ETA: 0s - loss: 5.0586 - accuracy: 0.0213\n","Epoch 00002: val_loss improved from 5.19451 to 5.00260, saving model to models/lstm.h5\n","66/66 [==============================] - 90s 1s/step - loss: 5.0586 - accuracy: 0.0213 - val_loss: 5.0026 - val_accuracy: 0.0246\n","Epoch 3/30\n","66/66 [==============================] - ETA: 0s - loss: 4.7516 - accuracy: 0.0443\n","Epoch 00003: val_loss improved from 5.00260 to 4.81247, saving model to models/lstm.h5\n","66/66 [==============================] - 89s 1s/step - loss: 4.7516 - accuracy: 0.0443 - val_loss: 4.8125 - val_accuracy: 0.0246\n","Epoch 4/30\n","66/66 [==============================] - ETA: 0s - loss: 4.4547 - accuracy: 0.0762\n","Epoch 00004: val_loss improved from 4.81247 to 4.66788, saving model to models/lstm.h5\n","66/66 [==============================] - 89s 1s/step - loss: 4.4547 - accuracy: 0.0762 - val_loss: 4.6679 - val_accuracy: 0.0424\n","Epoch 5/30\n","66/66 [==============================] - ETA: 0s - loss: 4.1504 - accuracy: 0.1167\n","Epoch 00005: val_loss improved from 4.66788 to 4.57451, saving model to models/lstm.h5\n","66/66 [==============================] - 90s 1s/step - loss: 4.1504 - accuracy: 0.1167 - val_loss: 4.5745 - val_accuracy: 0.0580\n","Epoch 6/30\n","66/66 [==============================] - ETA: 0s - loss: 3.8226 - accuracy: 0.1795\n","Epoch 00006: val_loss improved from 4.57451 to 4.49329, saving model to models/lstm.h5\n","66/66 [==============================] - 89s 1s/step - loss: 3.8226 - accuracy: 0.1795 - val_loss: 4.4933 - val_accuracy: 0.0781\n","Epoch 7/30\n","66/66 [==============================] - ETA: 0s - loss: 3.5183 - accuracy: 0.2401\n","Epoch 00007: val_loss improved from 4.49329 to 4.35114, saving model to models/lstm.h5\n","66/66 [==============================] - 89s 1s/step - loss: 3.5183 - accuracy: 0.2401 - val_loss: 4.3511 - val_accuracy: 0.0737\n","Epoch 8/30\n","66/66 [==============================] - ETA: 0s - loss: 3.2044 - accuracy: 0.3052\n","Epoch 00008: val_loss improved from 4.35114 to 4.34328, saving model to models/lstm.h5\n","66/66 [==============================] - 90s 1s/step - loss: 3.2044 - accuracy: 0.3052 - val_loss: 4.3433 - val_accuracy: 0.1049\n","Epoch 9/30\n","66/66 [==============================] - ETA: 0s - loss: 2.9051 - accuracy: 0.3871\n","Epoch 00009: val_loss improved from 4.34328 to 4.25960, saving model to models/lstm.h5\n","66/66 [==============================] - 89s 1s/step - loss: 2.9051 - accuracy: 0.3871 - val_loss: 4.2596 - val_accuracy: 0.1049\n","Epoch 10/30\n","66/66 [==============================] - ETA: 0s - loss: 2.6322 - accuracy: 0.4643\n","Epoch 00010: val_loss improved from 4.25960 to 4.24254, saving model to models/lstm.h5\n","66/66 [==============================] - 89s 1s/step - loss: 2.6322 - accuracy: 0.4643 - val_loss: 4.2425 - val_accuracy: 0.1205\n","Epoch 11/30\n","66/66 [==============================] - ETA: 0s - loss: 2.3966 - accuracy: 0.5268\n","Epoch 00011: val_loss improved from 4.24254 to 4.21600, saving model to models/lstm.h5\n","66/66 [==============================] - 89s 1s/step - loss: 2.3966 - accuracy: 0.5268 - val_loss: 4.2160 - val_accuracy: 0.1250\n","Epoch 12/30\n","66/66 [==============================] - ETA: 0s - loss: 2.1625 - accuracy: 0.5964\n","Epoch 00012: val_loss did not improve from 4.21600\n","66/66 [==============================] - 90s 1s/step - loss: 2.1625 - accuracy: 0.5964 - val_loss: 4.2827 - val_accuracy: 0.1473\n","Epoch 13/30\n","66/66 [==============================] - ETA: 0s - loss: 1.9717 - accuracy: 0.6458\n","Epoch 00013: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.9717 - accuracy: 0.6458 - val_loss: 4.3107 - val_accuracy: 0.1228\n","Epoch 14/30\n","66/66 [==============================] - ETA: 0s - loss: 1.8186 - accuracy: 0.6915\n","Epoch 00014: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.8186 - accuracy: 0.6915 - val_loss: 4.3974 - val_accuracy: 0.1518\n","Epoch 15/30\n","66/66 [==============================] - ETA: 0s - loss: 1.6580 - accuracy: 0.7384\n","Epoch 00015: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.6580 - accuracy: 0.7384 - val_loss: 4.4270 - val_accuracy: 0.1362\n","Epoch 16/30\n","66/66 [==============================] - ETA: 0s - loss: 1.5197 - accuracy: 0.7701\n","Epoch 00016: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.5197 - accuracy: 0.7701 - val_loss: 4.4865 - val_accuracy: 0.1384\n","Epoch 17/30\n","66/66 [==============================] - ETA: 0s - loss: 1.4018 - accuracy: 0.8111\n","Epoch 00017: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.4018 - accuracy: 0.8111 - val_loss: 4.5612 - val_accuracy: 0.1272\n","Epoch 18/30\n","66/66 [==============================] - ETA: 0s - loss: 1.2960 - accuracy: 0.8400\n","Epoch 00018: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.2960 - accuracy: 0.8400 - val_loss: 4.6497 - val_accuracy: 0.1429\n","Epoch 19/30\n","66/66 [==============================] - ETA: 0s - loss: 1.1920 - accuracy: 0.8681\n","Epoch 00019: val_loss did not improve from 4.21600\n","66/66 [==============================] - 90s 1s/step - loss: 1.1920 - accuracy: 0.8681 - val_loss: 4.6031 - val_accuracy: 0.1429\n","Epoch 20/30\n","66/66 [==============================] - ETA: 0s - loss: 1.1226 - accuracy: 0.8849\n","Epoch 00020: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.1226 - accuracy: 0.8849 - val_loss: 4.6828 - val_accuracy: 0.1384\n","Epoch 21/30\n","66/66 [==============================] - ETA: 0s - loss: 1.0728 - accuracy: 0.8909\n","Epoch 00021: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 1.0728 - accuracy: 0.8909 - val_loss: 4.6914 - val_accuracy: 0.1406\n","Epoch 22/30\n","66/66 [==============================] - ETA: 0s - loss: 0.9825 - accuracy: 0.9152\n","Epoch 00022: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 0.9825 - accuracy: 0.9152 - val_loss: 4.7093 - val_accuracy: 0.1496\n","Epoch 23/30\n","66/66 [==============================] - ETA: 0s - loss: 0.9164 - accuracy: 0.9302\n","Epoch 00023: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 0.9164 - accuracy: 0.9302 - val_loss: 4.7930 - val_accuracy: 0.1429\n","Epoch 24/30\n","66/66 [==============================] - ETA: 0s - loss: 0.8725 - accuracy: 0.9418\n","Epoch 00024: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 0.8725 - accuracy: 0.9418 - val_loss: 4.8066 - val_accuracy: 0.1518\n","Epoch 25/30\n","66/66 [==============================] - ETA: 0s - loss: 0.8395 - accuracy: 0.9446\n","Epoch 00025: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 0.8395 - accuracy: 0.9446 - val_loss: 4.8977 - val_accuracy: 0.1384\n","Epoch 26/30\n","66/66 [==============================] - ETA: 0s - loss: 0.7851 - accuracy: 0.9550\n","Epoch 00026: val_loss did not improve from 4.21600\n","66/66 [==============================] - 90s 1s/step - loss: 0.7851 - accuracy: 0.9550 - val_loss: 4.9068 - val_accuracy: 0.1384\n","Epoch 27/30\n","66/66 [==============================] - ETA: 0s - loss: 0.7522 - accuracy: 0.9602\n","Epoch 00027: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 0.7522 - accuracy: 0.9602 - val_loss: 4.8857 - val_accuracy: 0.1473\n","Epoch 28/30\n","66/66 [==============================] - ETA: 0s - loss: 0.7176 - accuracy: 0.9680\n","Epoch 00028: val_loss did not improve from 4.21600\n","66/66 [==============================] - 90s 1s/step - loss: 0.7176 - accuracy: 0.9680 - val_loss: 4.9354 - val_accuracy: 0.1272\n","Epoch 29/30\n","66/66 [==============================] - ETA: 0s - loss: 0.6820 - accuracy: 0.9744\n","Epoch 00029: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 0.6820 - accuracy: 0.9744 - val_loss: 4.7949 - val_accuracy: 0.1384\n","Epoch 30/30\n","66/66 [==============================] - ETA: 0s - loss: 0.6578 - accuracy: 0.9785\n","Epoch 00030: val_loss did not improve from 4.21600\n","66/66 [==============================] - 89s 1s/step - loss: 0.6578 - accuracy: 0.9785 - val_loss: 4.9567 - val_accuracy: 0.1362\n"],"name":"stdout"}]}]}